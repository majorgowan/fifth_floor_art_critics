{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd ../Python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import readPBNData.description as rd\n",
    "import readPBNData.images as ri\n",
    "import PBNFeatures.paletteTools as pt\n",
    "import PBNPCA.pca as pbnpca\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and sorting image- and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csvs, fileLike = rd.openZip('../Data/train_info.csv.zip')\n",
    "lines, head = rd.readCSV(fileLike[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = rd.columns(lines,head)\n",
    "cols.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find 10 artists with most paintings in data set\n",
    "artistTable = rd.table(cols['artist'])\n",
    "artistTable[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# images in train_1.zip and train_2.zip file\n",
    "train_1_names = rd.imagesInZip('../Data/train_1.zip')\n",
    "train_2_names = rd.imagesInZip('../Data/train_2.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show (full) image\n",
    "def showImage(imgName):\n",
    "    if (imgName in train_1_names):\n",
    "        ri.openZipImage('../Data/train_1.zip', \\\n",
    "                        imgName, \\\n",
    "                        prefix='train_1' \\\n",
    "                       ).show()\n",
    "    else:\n",
    "        ri.openZipImage('../Data/train_2.zip', \\\n",
    "                        imgName, \\\n",
    "                        prefix='train_2' \\\n",
    "                       ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create miniatures and cutout samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if it exists, load the json text file containing list of \n",
    "# 10 most prolific artists and the filenames of their paintings\n",
    "# contained in train_1.zip and train_2.zip, assume miniatures\n",
    "# and cutouts already exist (can refactor later to check)\n",
    "#\n",
    "# else, scan zip files, create miniatures, cutouts, json index file\n",
    "#\n",
    "import os.path\n",
    "import json\n",
    "featureDir = '../Data/'\n",
    "portfoliosFile = featureDir + 'portfolios_top10.json'\n",
    "if (os.path.isfile(portfoliosFile)):\n",
    "    with open(portfoliosFile,'r') as jsonfile:\n",
    "        portfolios_uni = json.load(jsonfile)\n",
    "        print('reading reading reading!!!')\n",
    "else:\n",
    "    # if json file doesn't exist, then go through steps to create\n",
    "    # miniatures and cutouts (if necessary) and then\n",
    "    # create json file\n",
    "\n",
    "    # number of paintings by artist in train_1 and train_2\n",
    "    # distinct artists (slowish)\n",
    "    distinctArtists = [a[0] for a in artistTable]\n",
    "    paintingsIn12 = []\n",
    "    print('scanning for paintings by top ten in full csv file . . .')\n",
    "    for artist in distinctArtists:\n",
    "        # print('    scanning artist ' + artist + ' . . . ')\n",
    "        paintingsIn12.append(len(rd.sameArtist(artist, cols, imageList=train_1_names))\n",
    "                            +len(rd.sameArtist(artist, cols, imageList=train_2_names)))\n",
    "    artistTable12 = sorted(zip(distinctArtists, paintingsIn12), \n",
    "                           key=lambda item: item[1], reverse=True)\n",
    "    print('top 10 artists . . . ')\n",
    "    print(artistTable12[:10])\n",
    "\n",
    "    # lists of paintings by the 10 most prolific artists in train_1 and train_2 \n",
    "    # extract artist names from artistTable\n",
    "    print('\\nscanning for paintings by top ten in zip files . . .')\n",
    "    leaders = [a[0] for a in artistTable12[:10]]\n",
    "    portfolios1 = []\n",
    "    portfolios2 = []\n",
    "    for artist in leaders:\n",
    "        print('    scanning artist ' + artist + ' . . . ')\n",
    "        # paintings in train_1.zip\n",
    "        portfolios1.append(rd.sameArtist(artist, cols, imageList=train_1_names))\n",
    "        # paintings in train_2.zip\n",
    "        portfolios2.append(rd.sameArtist(artist, cols, imageList=train_2_names))\n",
    "    # list of artists and (separate) lists of paintings in train_1 and train_2\n",
    "    portfolios = zip(leaders,portfolios1,portfolios2)\n",
    "    # list of artists and single list of paintings\n",
    "    portfolios_uni = [(artist, p1 + p2) for (artist,p1,p2) in portfolios]\n",
    "\n",
    "    # create miniatures of the paintings by most prolific artists and save them to disk\n",
    "    # (if file exists, does nothing)\n",
    "    print('\\ncreating miniatures (if necessary) . . . ')\n",
    "    for portfolio in portfolios:\n",
    "        print('    artist ' + portfolio[0] + ' . . . ')\n",
    "        minifiles_1 = ri.miniatures('../Data/train_1.zip', \\\n",
    "                                    portfolio[1],prefix='train_1',size=(100,100))\n",
    "        minifiles_2 = ri.miniatures('../Data/train_2.zip', \\\n",
    "                                    portfolio[2],prefix='train_2',size=(100,100))\n",
    "    # create cutouts of the paintings by most prolific artists and save them to disk\n",
    "    # (if file exists, does nothing)\n",
    "    print('\\ncreating cutouts (if necessary) . . . ')\n",
    "    for portfolio in portfolios:\n",
    "        print('    artist ' + portfolio[0] + ' . . . ')\n",
    "        cutoutfiles_1 = ri.cutouts('../Data/train_1.zip', \\\n",
    "                                   portfolio[1],prefix='train_1',size=(100,100))\n",
    "        cutoutfiles_2 = ri.cutouts('../Data/train_2.zip', \\\n",
    "                                   portfolio[2],prefix='train_2',size=(100,100))\n",
    "        \n",
    "    # create json text file with list of artists and filenames of paintings:\n",
    "    print('\\nwriting json index file . . .')\n",
    "    with open(portfoliosFile,'w') as jsonfile:\n",
    "        jsonfile.write(json.dumps(portfolios_uni,indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate random pairs of paintings by same and different paintings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare 1000 pairs of paintings by same artist \n",
    "# and 1000 pairs by different artists\n",
    "import random\n",
    "npairs = 1000\n",
    "randomSeed = 667\n",
    "random.seed(randomSeed)\n",
    "pairs = []\n",
    "for isample in xrange(npairs):\n",
    "    # randomly choose an artist\n",
    "    portfolio = random.choice(portfolios_uni)\n",
    "    # randomly choose two paintings\n",
    "    paintings = random.sample(portfolio[1],2)\n",
    "    pairs.append([paintings[0],paintings[1],1])\n",
    "for isample in xrange(npairs):\n",
    "    # randomly choose two artists\n",
    "    portfoliopair = random.sample(portfolios_uni,2)\n",
    "    # randomly choose a painting from each artist\n",
    "    paintings = random.choice(portfoliopair[0][1]), random.choice(portfoliopair[1][1])\n",
    "    pairs.append([paintings[0],paintings[1],0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate colour features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load all miniatures and simplify colour palette to 16-colour CGA\n",
    "# save filenames and pixel-counts by colour in two lists\n",
    "import PBNFeatures.paletteTools as pt\n",
    "import os.path\n",
    "import json\n",
    "from PIL import Image\n",
    "featureDir = '../Data/'\n",
    "nc = 16\n",
    "palette = pt.CGApalette(ncolours=nc)\n",
    "cgaColoursFile = featureDir + 'cgacolours_top10.json'\n",
    "namesFile = featureDir + 'names_top10.json'\n",
    "if (os.path.isfile(cgaColoursFile)):\n",
    "    with open(cgaColoursFile,'r') as jsonfile:\n",
    "        data = json.load(jsonfile)\n",
    "        print('reading CGA Colours file . . .')\n",
    "    with open(namesFile,'r') as jsonfile:\n",
    "        names = json.load(jsonfile)\n",
    "        print('reading names file . . .')\n",
    "else:\n",
    "    # load all miniatures and compute saturation, value and hue\n",
    "    # statistics for each (slow),\n",
    "    # save filenames and pixel-counts by colour in two lists\n",
    "    data = []\n",
    "    names = []\n",
    "    for portfolio in portfolios_uni:\n",
    "        print('processing paintings by artist ' + portfolio[0] + ' . . .')\n",
    "        for painting in portfolio[1]:\n",
    "            names.append(painting)\n",
    "            mininame = os.path.splitext(painting)[0] + '_mini_100_x_100.jpg'\n",
    "            mini = Image.open(featureDir + 'FeatureData/' + mininame)\n",
    "            minip = pt.paletteConvert(mini,palette)\n",
    "            colours = pt.completeColours(minip.getcolors(),nc)[:nc]\n",
    "            data.append([c[0] for c in colours])\n",
    "    # write cga colour data to json file\n",
    "    # artist's portfolio\n",
    "    print('\\nwriting json index file . . .')\n",
    "    with open(cgaColoursFile,'w') as jsonfile:\n",
    "        print('writing CGA colours file . . .')\n",
    "        jsonfile.write(json.dumps(data,indent=2))\n",
    "    with open(namesFile,'w') as jsonfile:\n",
    "        print('writing names file . . .')\n",
    "        jsonfile.write(json.dumps(names,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load a single pair of miniatures\n",
    "def loadPair(pair, mc = 'mini'):\n",
    "    import os.path\n",
    "    import PIL.Image as Image\n",
    "    featureDir = '../Data/FeatureData/'\n",
    "    name0 = os.path.splitext(pair[0])[0] + '_' + mc + '_100_x_100.jpg'\n",
    "    mini0 = Image.open(featureDir + name0)\n",
    "    name1 = os.path.splitext(pair[1])[0]+'_' + mc + '_100_x_100.jpg'\n",
    "    mini1 = Image.open(featureDir + name1)\n",
    "    return mini0, mini1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load a pair by the same artist\n",
    "pairnum = 999\n",
    "mini1, mini2 = loadPair(pairs[pairnum])\n",
    "# show (full) images\n",
    "#showImage(pairs[pairnum][0])\n",
    "#showImage(pairs[pairnum][1])\n",
    "\n",
    "\n",
    "# compare colour distribution in simplified palette between\n",
    "# members of the pair\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "palette = pt.CGApalette(ncolours=16)\n",
    "\n",
    "mini1p = pt.paletteConvert(mini1,palette)\n",
    "mini2p = pt.paletteConvert(mini2,palette)\n",
    "\n",
    "pt.plotColourDistribution(mini1p.getcolors(),pt.unflatten(palette))\n",
    "pt.plotColourDistribution(mini2p.getcolors(),pt.unflatten(palette))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# repeat for a pair by different artists\n",
    "# load a pair by the same artist\n",
    "pairnum = 1001\n",
    "mini1, mini2 = loadPair(pairs[pairnum])\n",
    "# show (full) images\n",
    "#showImage(pairs[pairnum][0])\n",
    "#showImage(pairs[pairnum][1])\n",
    "\n",
    "mini1p = pt.paletteConvert(mini1,palette)\n",
    "mini2p = pt.paletteConvert(mini2,palette)\n",
    "\n",
    "pt.plotColourDistribution(mini1p.getcolors(),pt.unflatten(palette))\n",
    "pt.plotColourDistribution(mini2p.getcolors(),pt.unflatten(palette))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise comparisons based on CGA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for all pairs in \"pairs\", compute distances in colour space\n",
    "import math\n",
    "distance = []\n",
    "for pair in pairs:\n",
    "    inds = names.index(pair[0]), names.index(pair[1])\n",
    "    distance.append(sum((x1-data[inds[1]][i])**2 for i,x1 in enumerate(data[inds[0]])))\n",
    "print('mean distance for sames, diffs:')\n",
    "print(np.mean(distance[:npairs]), np.mean(distance[-npairs:]))\n",
    "print('\\n')\n",
    "\n",
    "# plot Euclidean distance in pixel-count space for\n",
    "# pairs that are by same artist (blue) and\n",
    "# pairs that are by different artists (red)\n",
    "# (not very exciting!)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.plot(range(npairs),distance[:npairs],linestyle='none',color='blue',marker='.')\n",
    "plt.plot(range(npairs,2*npairs),distance[-npairs:],linestyle='none',color='red',marker='.')\n",
    "plt.title('Distance in 16-colour pixel-count space\\n' \\\n",
    "        +'same painter (blue), different painter (red)')\n",
    "plt.xlabel('pair number')\n",
    "plt.show()\n",
    "\n",
    "# repeat with a different norm ... (but which?)\n",
    "# what about just rank difference by colour\n",
    "distance2 = []\n",
    "ncol = len(data[0])\n",
    "for pair in pairs:\n",
    "    inds = names.index(pair[0]), names.index(pair[1])\n",
    "    ranks1 = [aa[1] for aa in sorted(zip(data[inds[0]],range(ncol)))]\n",
    "    ranks2 = [aa[1] for aa in sorted(zip(data[inds[1]],range(ncol)))]\n",
    "    distance2.append(sum((r - ranks2[i])**2 for i,r in enumerate(ranks1)))\n",
    "print('mean distance for sames, diffs:')\n",
    "print(np.mean(distance2[:npairs]), np.mean(distance2[-npairs:]))\n",
    "print('\\n')\n",
    "\n",
    "# plot rank distance in pixel-count space for\n",
    "# pairs that are by same artist (blue) and\n",
    "# pairs that are by different artists (red)\n",
    "# (not exciting at all!!)\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.plot(range(npairs),distance2[:npairs],linestyle='none',color='blue',marker='.')\n",
    "plt.plot(range(npairs,2*npairs),distance2[-npairs:],linestyle='none',color='red',marker='.')\n",
    "plt.title('Distance in 16-colour pixel-count \\\"rank\\\" space\\n' \\\n",
    "        +'same painter (blue), different painter (red)')\n",
    "plt.xlabel('pair number')\n",
    "plt.show()\n",
    "\n",
    "# repeat with yet another different norm ... (but which?)\n",
    "# what about on/off switch if colour is more than 5%\n",
    "distance3 = []\n",
    "ncol = len(data[0])\n",
    "thresh = 0.05*sum(data[0])\n",
    "for pair in pairs:\n",
    "    inds = names.index(pair[0]), names.index(pair[1])\n",
    "    onoff1 = [int(x>thresh) for x in data[inds[0]]]\n",
    "    onoff2 = [int(x>thresh) for x in data[inds[1]]]\n",
    "    distance3.append(sum((r - onoff2[i])**2 for i,r in enumerate(onoff1)))\n",
    "print('mean distance for sames, diffs:')\n",
    "print(np.mean(distance3[:npairs]), np.mean(distance3[-npairs:]))\n",
    "print('\\n')\n",
    "\n",
    "# plot distance in threshold space for\n",
    "# pairs that are by same artist (blue) and\n",
    "# pairs that are by different artists (red)\n",
    "# (slightly more exciting :-())\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.plot(range(npairs),distance3[:npairs],linestyle='none',color='blue',marker='.')\n",
    "plt.plot(range(npairs,2*npairs),distance3[-npairs:],linestyle='none',color='red',marker='.')\n",
    "plt.title('Distance in 16-colour pixel-count number-of-colours space\\n' \\\n",
    "        +'same painter (blue), different painter (red)')\n",
    "plt.xlabel('pair number')\n",
    "plt.show()\n",
    "\n",
    "# repeat with yet another different norm ... (but which?)\n",
    "# what about on/off switch if colour is more than 5%\n",
    "# but this time count only common colours\n",
    "distance4 = []\n",
    "ncol = len(data[0])\n",
    "thresh = 0.05*sum(data[0])\n",
    "for pair in pairs:\n",
    "    inds = names.index(pair[0]), names.index(pair[1])\n",
    "    onoff1 = [int(x>thresh) for x in data[inds[0]]]\n",
    "    onoff2 = [int(x>thresh) for x in data[inds[1]]]\n",
    "    distance4.append(sum(int(r+onoff2[i]==2) for i,r in enumerate(onoff1)))\n",
    "print('mean distance for sames, diffs:')\n",
    "print(np.mean(distance4[:npairs]), np.mean(distance4[-npairs:]))\n",
    "print('\\n')\n",
    "\n",
    "# plot distance in threshold space for\n",
    "# pairs that are by same artist (blue) and\n",
    "# pairs that are by different artists (red)\n",
    "# (slightly more exciting :-())\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.plot(range(npairs),distance4[:npairs],linestyle='none',color='blue',marker='.')\n",
    "plt.plot(range(npairs,2*npairs),distance4[-npairs:],linestyle='none',color='red',marker='.')\n",
    "plt.title('Distance in number-of-colours-in-comon space\\n' \\\n",
    "        +'same painter (blue), different painter (red)')\n",
    "plt.xlabel('pair number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Was ist hier eigentlich los????\n",
    "# Let's look at particular pairs\n",
    "pairnum = 7\n",
    "inds = names.index(pairs[pairnum][0]), names.index(pairs[pairnum][1])\n",
    "\n",
    "# show (full) images\n",
    "#showImage(pairs[pairnum][0])\n",
    "#showImage(pairs[pairnum][1])\n",
    "\n",
    "# distance1\n",
    "print('Euclidean')\n",
    "print(zip(data[inds[0]],data[inds[1]]))\n",
    "print(distance[pairnum])\n",
    "\n",
    "# distance2\n",
    "print('\\nRank')\n",
    "ranks1 = [aa[1] for aa in sorted(zip(data[inds[0]],range(ncol)))]\n",
    "ranks2 = [aa[1] for aa in sorted(zip(data[inds[1]],range(ncol)))]\n",
    "print(zip(ranks1,ranks2))\n",
    "print(distance2[pairnum])\n",
    "\n",
    "\n",
    "# distance3\n",
    "print('\\nThreshold')\n",
    "onoff1 = [int(x>thresh) for x in data[inds[0]]]\n",
    "onoff2 = [int(x>thresh) for x in data[inds[1]]]\n",
    "print(zip(onoff1,onoff2))\n",
    "print(distance3[pairnum])\n",
    "\n",
    "# distance4\n",
    "print('\\nCommon Threshold')\n",
    "onoff1 = [int(x>thresh) for x in data[inds[0]]]\n",
    "onoff2 = [int(x>thresh) for x in data[inds[1]]]\n",
    "print(zip(onoff1,onoff2))\n",
    "print(distance4[pairnum])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise comparisons based on HSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# maybe hue/saturation/value is more interesting!!!\n",
    "import PBNFeatures.cylindrical as cyl\n",
    "reload(cyl)\n",
    "\n",
    "pairnum=999\n",
    "\n",
    "# show (full) images\n",
    "#showImage(pairs[pairnum][0])\n",
    "#showImage(pairs[pairnum][1])\n",
    "\n",
    "# load miniatures\n",
    "mini1,mini2 = loadPair(pairs[pairnum],mc='mini')\n",
    "\n",
    "# compute hue/saturation/value statistics\n",
    "hsvstats1 = cyl.hsv_stats(cyl.jpg_to_hsv(mini1),hue_bins=8)\n",
    "hsvstats2 = cyl.hsv_stats(cyl.jpg_to_hsv(mini2),hue_bins=8)\n",
    "\n",
    "# histograms of hue distribution\n",
    "reload(cyl)\n",
    "cyl.plotHueDistribution(hsvstats1['hue_bins'])\n",
    "cyl.plotHueDistribution(hsvstats2['hue_bins'])\n",
    "\n",
    "# hsvstats1, hsvstats2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if it exists, load the json text file containing list of \n",
    "# 10 most prolific artists and the hsv stats of their paintings\n",
    "# contained in train_1.zip and train_2.zip\n",
    "#\n",
    "# else, process all miniatures and write json file\n",
    "#\n",
    "import PBNFeatures.cylindrical as cyl\n",
    "from PIL import Image\n",
    "import os.path\n",
    "import json\n",
    "featureDir = '../Data/'\n",
    "hsvstatsFile = featureDir + 'hsvstats_top10.json'\n",
    "namesFile = featureDir + 'names_top10.json'\n",
    "if (os.path.isfile(hsvstatsFile)):\n",
    "    with open(hsvstatsFile,'r') as jsonfile:\n",
    "        hsvstats = json.load(jsonfile)\n",
    "        print('reading hsvstats file . . .')\n",
    "    with open(namesFile,'r') as jsonfile:\n",
    "        names = json.load(jsonfile)\n",
    "        print('reading names file . . .')\n",
    "else:\n",
    "    # load all miniatures and compute saturation, value and hue\n",
    "    # statistics for each (slow),\n",
    "    # save filenames and pixel-counts by colour in two lists\n",
    "    hsvstats = []\n",
    "    names = []\n",
    "    for portfolio in portfolios_uni:\n",
    "        print('processing paintings by artist ' + portfolio[0] + ' . . .')\n",
    "        for painting in portfolio[1]:\n",
    "            names.append(painting)\n",
    "            mininame = os.path.splitext(painting)[0] + '_mini_100_x_100.jpg'\n",
    "            mini = Image.open(featureDir + 'FeatureData/' + mininame)\n",
    "            hsvstats.append(cyl.hsv_stats(cyl.jpg_to_hsv(mini),hue_bins=16))\n",
    "    # write hsvstats to json file\n",
    "    # create json text file with list of hsv stats for each\n",
    "    # artist's portfolio\n",
    "    print('\\nwriting json index file . . .')\n",
    "    with open(hsvstatsFile,'w') as jsonfile:\n",
    "        print('writing hsvstats file . . .')\n",
    "        jsonfile.write(json.dumps(hsvstats,indent=2))\n",
    "    with open(namesFile,'w') as jsonfile:\n",
    "        print('writing names file . . .')\n",
    "        jsonfile.write(json.dumps(names,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's look at some hsv statistics for a set of paintings\n",
    "# (whole population or a single painter, or whatever)\n",
    "%matplotlib inline\n",
    "def hsvStatsPlots(hsvst, nbins=20):\n",
    "    sat_means = [h['sat_mean'] for h in hsvst]\n",
    "    sat_stds = [h['sat_std'] for h in hsvst]\n",
    "    val_means = [h['val_mean'] for h in hsvst]\n",
    "    val_stds = [h['val_std'] for h in hsvst]\n",
    "    dom_hue = [h['hue_bins'][0][0] for h in hsvst]\n",
    "    dom_hue_count = [h['hue_bins'][0][1] for h in hsvst]\n",
    "    hue_variety = [sum(int(hue[1]>1000) for hue in h['hue_bins']) for h in hsvst]\n",
    "\n",
    "\n",
    "    # histograms\n",
    "    import matplotlib.pyplot as plt\n",
    "    n, bins, patches = plt.hist(sat_means, bins=nbins, normed=True, facecolor='green', alpha=0.75)\n",
    "    plt.xlabel('Mean saturation')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    n, bins, patches = plt.hist(sat_stds, bins=nbins, normed=True, facecolor='red', alpha=0.75)\n",
    "    plt.xlabel('Saturation std')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    n, bins, patches = plt.hist(val_means, bins=nbins, normed=True, facecolor='blue', alpha=0.75)\n",
    "    plt.xlabel('Mean value (brightness)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    n, bins, patches = plt.hist(val_stds, bins=nbins, normed=True, facecolor='green', alpha=0.75)\n",
    "    plt.xlabel('Value (brightness) std')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    n, bins, patches = plt.hist(dom_hue_count, bins=nbins, normed=True, facecolor='red', alpha=0.75)\n",
    "    plt.xlabel('Pixels of dominant hue')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # barplots\n",
    "    tab = rd.table(hue_variety)\n",
    "    wid = 0.8\n",
    "    pos = [t[0] for t in tab]\n",
    "    heights = [t[1] for t in tab]\n",
    "    plt.xlabel('Number of important hue bins (out of 16)')\n",
    "    plt.bar(pos, heights, width=wid)\n",
    "    plt.show()\n",
    "\n",
    "    tab = rd.table(dom_hue)\n",
    "    cyl.plotHueDistribution(tab, nhues=16)\n",
    "    plt.title('Occurrence of dominant hues')\n",
    "    plt.ylabel('occurrence')\n",
    "    plt.xlim([0,16])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stats for full population\n",
    "hsvStatsPlots(hsvstats, nbins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# painter 2\n",
    "painterNum = 2\n",
    "paintings = portfolios_uni[painterNum][1]\n",
    "hsvst = [hsvstats[names.index(p)] for p in paintings]\n",
    "hsvStatsPlots(hsvst, nbins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# painter 3\n",
    "painterNum = 3\n",
    "paintings = portfolios_uni[painterNum][1]\n",
    "hsvst = [hsvstats[names.index(p)] for p in paintings]\n",
    "\n",
    "hsvStatsPlots(hsvst, nbins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for all pairs in \"pairs\", compute difference in \n",
    "# saturation and value means and std and the\n",
    "# distance in dominant hue\n",
    "import math\n",
    "sat_mean_dist = []\n",
    "sat_std_dist = []\n",
    "val_mean_dist = []\n",
    "val_std_dist = []\n",
    "total_hue_dist = []\n",
    "dom_hue_dist = []\n",
    "dom_hue_count_dist = []\n",
    "hue_variety_dist = []\n",
    "nbins = len(hsvstats[0]['hue_bins'])\n",
    "hue_ave = sum(pix for i,pix in hsvstats[0]['hue_bins'])/nbins\n",
    "\n",
    "for pair in pairs:\n",
    "    inds = names.index(pair[0]), names.index(pair[1])\n",
    "    sat_mean_dist.append( \\\n",
    "                abs(hsvstats[inds[0]]['sat_mean'] - hsvstats[inds[1]]['sat_mean']))\n",
    "    sat_std_dist.append( \\\n",
    "                abs(hsvstats[inds[0]]['sat_std'] - hsvstats[inds[1]]['sat_std']))\n",
    "    val_mean_dist.append( \\\n",
    "                abs(hsvstats[inds[0]]['val_mean'] - hsvstats[inds[1]]['val_mean']))\n",
    "    val_std_dist.append( \\\n",
    "                abs(hsvstats[inds[0]]['val_std'] - hsvstats[inds[1]]['val_std']))\n",
    "    hues1 = cyl.completeSortHues(hsvstats[inds[0]]['hue_bins'],nhues=16)\n",
    "    hues2 = cyl.completeSortHues(hsvstats[inds[1]]['hue_bins'],nhues=16)\n",
    "    total_hue_dist.append( \\\n",
    "                sum((x1[1]-hues2[i][1])**2 for i,x1 in enumerate(hues1)))\n",
    "    dom_hue_dist.append( \\\n",
    "                min( \\\n",
    "                    (hsvstats[inds[0]]['hue_bins'][0][0] - \\\n",
    "                     hsvstats[inds[1]]['hue_bins'][0][0]) % nbins, \\\n",
    "                    (hsvstats[inds[1]]['hue_bins'][0][0] - \\\n",
    "                     hsvstats[inds[0]]['hue_bins'][0][0]) % nbins) )\n",
    "    dom_hue_count_dist.append( \\\n",
    "                abs(hsvstats[inds[0]]['hue_bins'][0][1] - \\\n",
    "                    hsvstats[inds[1]]['hue_bins'][0][1]) )\n",
    "    # number of hue bins with more than the average number of pixels\n",
    "    hue_variety_dist.append( \\\n",
    "                abs(sum(int(h[1]>1000) \\\n",
    "                        for h in hsvstats[inds[0]]['hue_bins']) - \\\n",
    "                    sum(int(h[1]>1000) \\\n",
    "                        for h in hsvstats[inds[1]]['hue_bins']) ) )\n",
    "\n",
    "print('mean distances for sames, diffs:\\n')\n",
    "print('sat_mean:')\n",
    "print(np.mean(sat_mean_dist[:npairs]), np.mean(sat_mean_dist[-npairs:]))\n",
    "print('sat_std:')\n",
    "print(np.mean(sat_std_dist[:npairs]), np.mean(sat_std_dist[-npairs:]))\n",
    "print('val_mean:')\n",
    "print(np.mean(val_mean_dist[:npairs]), np.mean(val_mean_dist[-npairs:]))\n",
    "print('val_std:')\n",
    "print(np.mean(val_std_dist[:npairs]), np.mean(val_std_dist[-npairs:]))\n",
    "print('total_hue_dist:')\n",
    "print(np.mean(total_hue_dist[:npairs]), np.mean(total_hue_dist[-npairs:]))\n",
    "print('dom_hue:')\n",
    "print(np.mean(dom_hue_dist[:npairs]), np.mean(dom_hue_dist[-npairs:]))\n",
    "print('dom_hue_count:')\n",
    "print(np.mean(dom_hue_count_dist[:npairs]), np.mean(dom_hue_count_dist[-npairs:]))\n",
    "print('hue_variety:')\n",
    "print(np.mean(hue_variety_dist[:npairs]), np.mean(hue_variety_dist[-npairs:]))\n",
    "print('\\n')\n",
    "\n",
    "# plot Euclidean distance in hsv-stats space for\n",
    "# pairs that are by same artist (blue) and\n",
    "# pairs that are by different artists (red)\n",
    "# (still not very exciting!)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.plot(range(npairs),sat_mean_dist[:npairs],linestyle='none',color='blue',marker='.')\n",
    "plt.plot(range(npairs,2*npairs),sat_mean_dist[-npairs:],linestyle='none',color='red',marker='.')\n",
    "plt.title('Difference in mean-saturation\\n' \\\n",
    "        +'same painter (blue), different painter (red)')\n",
    "plt.xlabel('pair number')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.plot(range(npairs),val_mean_dist[:npairs],linestyle='none',color='blue',marker='.')\n",
    "plt.plot(range(npairs,2*npairs),val_mean_dist[-npairs:],linestyle='none',color='red',marker='.')\n",
    "plt.title('Difference in mean-value (brightness)\\n' \\\n",
    "        +'same painter (blue), different painter (red)')\n",
    "plt.xlabel('pair number')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.plot(range(npairs),total_hue_dist[:npairs],linestyle='none',color='blue',marker='.')\n",
    "plt.plot(range(npairs,2*npairs),total_hue_dist[-npairs:],linestyle='none',color='red',marker='.')\n",
    "plt.title('Eucl. dist. between hue distributions (16 bins)\\n' \\\n",
    "        +'same painter (blue), different painter (red)')\n",
    "plt.xlabel('pair number')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.plot(range(npairs),dom_hue_dist[:npairs],linestyle='none',color='blue',marker='.')\n",
    "plt.plot(range(npairs,2*npairs),dom_hue_dist[-npairs:],linestyle='none',color='red',marker='.')\n",
    "plt.title('Difference in dominant hue (1 of 16 bins)\\n' \\\n",
    "        +'same painter (blue), different painter (red)')\n",
    "plt.xlabel('pair number')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.plot(range(npairs),dom_hue_count_dist[:npairs],linestyle='none',color='blue',marker='.')\n",
    "plt.plot(range(npairs,2*npairs),dom_hue_count_dist[-npairs:],linestyle='none',color='red',marker='.')\n",
    "plt.title('Difference in pixels in the dominant hue (1 of 16 bins)\\n' \\\n",
    "        +'same painter (blue), different painter (red)')\n",
    "plt.xlabel('pair number')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.plot(range(npairs),hue_variety_dist[:npairs],linestyle='none',color='blue',marker='.')\n",
    "plt.plot(range(npairs,2*npairs),hue_variety_dist[-npairs:],linestyle='none',color='red',marker='.')\n",
    "plt.title('Difference in number of significant hues (of 16 bins)\\n' \\\n",
    "        +'same painter (blue), different painter (red)')\n",
    "plt.xlabel('pair number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Generate texture features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PBNFeatures.textureTools as tt\n",
    "reload(tt)\n",
    "reload(cyl)\n",
    "\n",
    "pairnum = 500\n",
    "\n",
    "# load cutouts\n",
    "cutout1,cutout2 = loadPair(pairs[pairnum],mc='cutout')\n",
    "print(cutout1.size)\n",
    "\n",
    "# display cutout1\n",
    "cutout1.show()\n",
    "\n",
    "# compute tuple of hue/saturation/value for each pixel\n",
    "hsvlist1 = cyl.jpg_to_hsv(cutout1)\n",
    "\n",
    "# smooth the value channel, rebuild and display\n",
    "hsvlist1 = tt.defocusValue(hsvlist1)\n",
    "cutout1.putdata(cyl.hsv_to_rgb(hsvlist1))\n",
    "cutout1.show()\n",
    "\n",
    "# again\n",
    "hsvlist1 = tt.defocusValue(hsvlist1)\n",
    "cutout1.putdata(cyl.hsv_to_rgb(hsvlist1))\n",
    "cutout1.show()\n",
    "\n",
    "# again\n",
    "hsvlist1 = tt.defocusValue(hsvlist1)\n",
    "cutout1.putdata(cyl.hsv_to_rgb(hsvlist1))\n",
    "cutout1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if it exists, load the json text file containing list of \n",
    "# 10 most prolific artists and the focus stats of their paintings\n",
    "# contained in train_1.zip and train_2.zip\n",
    "#\n",
    "# else, process all cutouts and write json file\n",
    "#\n",
    "import PBNFeatures.cylindrical as cyl\n",
    "import PBNFeatures.textureTools as tt\n",
    "from PIL import Image\n",
    "import os.path\n",
    "import json\n",
    "featureDir = '../Data/'\n",
    "focusstatsFile = featureDir + 'focusstats_top10.json'\n",
    "namesFile = featureDir + 'names_top10.json'\n",
    "if (os.path.isfile(focusstatsFile)):\n",
    "    with open(focusstatsFile,'r') as jsonfile:\n",
    "        focusstats = json.load(jsonfile)\n",
    "        print('reading hsvstats file . . .')\n",
    "    with open(namesFile,'r') as jsonfile:\n",
    "        names = json.load(jsonfile)\n",
    "        print('reading names file . . .')\n",
    "else:\n",
    "    # load all cutouts and compute\n",
    "    # the sharpness and the change in \n",
    "    # sharpness after smoothing twice each with \n",
    "    # both a 3-pixel and 5-pixel window\n",
    "    #\n",
    "    # save filenames and focus stats by colour in two lists\n",
    "    focusstats = []\n",
    "    names = []\n",
    "    for portfolio in portfolios_uni:\n",
    "        print('processing paintings by artist ' + portfolio[0] + ' . . .')\n",
    "        for painting in portfolio[1]:\n",
    "            #print(painting)\n",
    "            names.append(painting)\n",
    "            cutoutname = os.path.splitext(painting)[0] + '_cutout_100_x_100.jpg'\n",
    "            cutout = Image.open(featureDir + 'FeatureData/' + cutoutname)\n",
    "            #print('1 - image open')\n",
    "            # convert image data to hsvlist\n",
    "            hsvlist = cyl.jpg_to_hsv(cutout)\n",
    "            #print('2 - to hsv')\n",
    "            # compute sharpness\n",
    "            sharp0 = tt.focusDetect(hsvlist,size=cutout.size)\n",
    "            #print('3 - focus detect')\n",
    "            sharp1 = [sharp0]\n",
    "            sharp2 = [sharp0]\n",
    "            # smooth with a 1-pixel window twice \n",
    "            hsvlist_s = tt.defocusValue(hsvlist,size=cutout.size,window=1)\n",
    "            #print('4 - defocusValue')\n",
    "            sharp1.append(tt.focusDetect(hsvlist_s,size=cutout.size))\n",
    "            hsvlist_s = tt.defocusValue(hsvlist_s,size=cutout.size,window=1)\n",
    "            #print('5 - defocusValue')\n",
    "            sharp1.append(tt.focusDetect(hsvlist_s,size=cutout.size))\n",
    "            # smooth with a 2-pixel window twice \n",
    "            hsvlist_s = tt.defocusValue(hsvlist,size=cutout.size,window=2)\n",
    "            #print('6 - defocusValue')\n",
    "            sharp2.append(tt.focusDetect(hsvlist_s,size=cutout.size))\n",
    "            hsvlist_s = tt.defocusValue(hsvlist_s,size=cutout.size,window=2)\n",
    "            #print('7 - defocusValue')\n",
    "            sharp2.append(tt.focusDetect(hsvlist_s,size=cutout.size))\n",
    "            # add focus stats to list\n",
    "            focusstats.append({'sharp1': sharp1, 'sharp2': sharp2})\n",
    "    # write focusstats to json file\n",
    "    # create json text file with list of hsv stats for each\n",
    "    # artist's portfolio\n",
    "    print('\\nwriting json index file . . .')\n",
    "    with open(focusstatsFile,'w') as jsonfile:\n",
    "        print('writing focusstats file . . .')\n",
    "        jsonfile.write(json.dumps(focusstats,indent=2))\n",
    "    with open(namesFile,'w') as jsonfile:\n",
    "        print('writing names file . . .')\n",
    "        jsonfile.write(json.dumps(names,indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's try a logistic regression using a few of the features\n",
    "# that look a tiny bit promisingimport numpy as np\n",
    "import Predictors.logRegres as lr\n",
    "reload(lr)\n",
    "featureMat = np.matrix([ \\\n",
    "                        len(distance)*[1.0], \\\n",
    "                        distance, \\\n",
    "                        distance3, \\\n",
    "                        sat_mean_dist, \\\n",
    "                        sat_std_dist, \\\n",
    "                        val_mean_dist, \\\n",
    "                        total_hue_dist, \\\n",
    "                        dom_hue_dist, \\\n",
    "                       ]).transpose()\n",
    "classLabels = [pair[2] for pair in pairs]\n",
    "\n",
    "# partition features and classes into training\n",
    "# and testing sets\n",
    "splitRatio = 0.8\n",
    "ntrain = int(0.5*splitRatio*len(featureMat))\n",
    "\n",
    "featureTrain = np.concatenate((featureMat[:ntrain],featureMat[-ntrain:]),axis=0)\n",
    "classTrain = np.concatenate((classLabels[:ntrain],classLabels[-ntrain:]),axis=0)\n",
    "\n",
    "featureTest = featureMat[ntrain:-ntrain]\n",
    "classTest = classLabels[ntrain:-ntrain]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# standardize (centre and normalize) training data\n",
    "obj = lr.standardize(featureTrain[:,1:])\n",
    "# apply same transformation to testing data\n",
    "lr.standardize_predict(featureTest[:,1:],obj)\n",
    "\n",
    "# train logistic regression model\n",
    "weights = lr.gradAscent(featureTrain,classTrain,alpha=0.001,iterations=200,report=75)\n",
    "# print out weights\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# in-sample predictions\n",
    "reload(lr)\n",
    "predictTrain = lr.predict(featureTrain,weights)\n",
    "trainConfusion = lr.confusion(classTrain,predictTrain,0.5)\n",
    "print(trainConfusion)\n",
    "print('\\nin-sample accuracy: ' + str(float(np.trace(trainConfusion))/np.sum(trainConfusion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# out-of-sample predictions\n",
    "predictTest = lr.predict(featureTest,weights)\n",
    "testConfusion = lr.confusion(classTest,predictTest,0.5)\n",
    "print(testConfusion)\n",
    "print('\\nout-of-sample accuracy: ' + str(float(np.trace(testConfusion))/np.sum(testConfusion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# maximum confidence prediction same artist\n",
    "print((np.argmax(predictTest), max(predictTest)))\n",
    "print(featureTest[np.argmax(predictTest)])\n",
    "\n",
    "showImage(pairs[ntrain+np.argmax(predictTest)][0])\n",
    "showImage(pairs[ntrain+np.argmax(predictTest)][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# maximum confidence prediction different artist\n",
    "print((np.argmin(predictTest), min(predictTest)))\n",
    "print(featureTest[np.argmin(predictTest)])\n",
    "\n",
    "showImage(pairs[ntrain+np.argmin(predictTest)][0])\n",
    "showImage(pairs[ntrain+np.argmin(predictTest)][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "rocObj = lr.ROC(classTrain,predictTrain, step=0.1)\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.xlabel('False Positive')\n",
    "plt.ylabel('True Positive')\n",
    "plt.plot(rocObj['fpr'],rocObj['tpr'])\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute PCA for 16-colour CGA colour distributions in miniatures\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PBNFeatures.paletteTools as pt\n",
    "import PBNPCA.pca as pbnpca\n",
    "import os.path\n",
    "import PIL.Image as Image\n",
    "#import math\n",
    "palette = pt.CGApalette(ncolours=16)\n",
    "nc = len(palette)/3\n",
    "featureDir = '../Data/FeatureData/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute the PC of data\n",
    "reload(pbnpca)\n",
    "ncomp = 15\n",
    "pobj = pbnpca.pca(np.array(data),ncomp)\n",
    "\n",
    "# pc:\n",
    "pcs = []\n",
    "for col in xrange(ncomp-1,-1,-1):\n",
    "    # column to row\n",
    "    pc = [vec[col] for vec in pobj['eigvecs']]\n",
    "    # construct a \"colours\" list out of the pc (clumsy but should be okay)\n",
    "    pc = [(a,i) for i,a in enumerate(pc)]\n",
    "    pcs.append(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot leading eigenvectors (PC)\n",
    "pt.plotColourDistribution(pcs[0],pt.unflatten(palette))\n",
    "pt.plotColourDistribution(pcs[1],pt.unflatten(palette))\n",
    "pt.plotColourDistribution(pcs[2],pt.unflatten(palette))\n",
    "pt.plotColourDistribution(pcs[3],pt.unflatten(palette))\n",
    "pt.plotColourDistribution(pcs[4],pt.unflatten(palette))\n",
    "pt.plotColourDistribution(pcs[5],pt.unflatten(palette))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# project row onto leading PC\n",
    "pbnpca.pcaProject(data[750],pobj)[-8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare full vector and projection onto first 8\n",
    "print(data[750])\n",
    "print('\\n')\n",
    "print(pbnpca.pcaTrunc(data[750],pobj,8))\n",
    "\n",
    "#np.zeros((len(data[0]),1))\n",
    "#np.array(pobj['meanvec']).reshape((len(data[0]),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ideas for other features ...\n",
    "#    saturation, lightness\n",
    "#    texture, edges, dots\n",
    "#    size\n",
    "#    number of significant colours\n",
    "# neural network idea?  (Auto-encoder-decoder)\n",
    "# topic (=style) modelling\n",
    "\n",
    "# contrast detection, \"focus and sharpness\""
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}